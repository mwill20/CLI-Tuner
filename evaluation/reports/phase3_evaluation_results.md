# Phase 3: Evaluation Results

## Executive Summary

**Overall Status:** FAIL
**Evaluation Date:** 2026-01-19
**Checkpoint:** models/checkpoints/phase2-final
**Test Set:** 174 examples

### Key Findings
- Exact Match Accuracy: 0.132
- Command-Only Rate: 0.994
- Dangerous Commands: 0
- Improvement over Base: +0.132

---

## 1. Domain-Specific Metrics

| Metric | Value | Threshold | Status |
| --- | --- | --- | --- |
| Exact Match Accuracy | 0.132 | >= 0.70 | FAIL |
| Command-Only Rate | 0.994 | >= 0.95 | PASS |
| Syntax Validity | None | >= 0.90 | SKIPPED |

**Successful Generations:** 174
**Failed Generations:** 0

---

## 2. Safety Validation

**Test Set:**
- Dangerous commands generated: 0
- Status: PASS

**Adversarial Prompts:**
- Safe responses: 12/21
- Status: FAIL

---

## 3. Base Model Comparison

| Metric | Base Model | Fine-Tuned | Improvement |
| --- | --- | --- | --- |
| Exact Match | 0.000 | 0.132 | +0.132 |

---

## 4. General Capability Retention (Optional)

*General benchmarks not run.*

---

## 5. Success Criteria Checklist

- Exact match accuracy >= 70%: FAIL
- Command-only rate >= 95%: PASS
- Syntax validity >= 90%: SKIPPED
- Zero dangerous commands: PASS
- Improvement over base: PASS
- Evaluation completed: PASS

**Overall:** FAIL

---

## 6. Artifacts

- Domain results: `evaluation/domain/results.jsonl`
- Safety metrics: `evaluation/safety/metrics.json`
- Comparison: `evaluation/comparison/base_vs_finetuned.json`
- Provenance: `evaluation/provenance.json`

---

Generated by `scripts/generate_eval_report.py` at 2026-01-19T15:58:59.212261+00:00
