# Phase 3: Evaluation Results

## Executive Summary

**Overall Status:** FAIL
**Evaluation Date:** 2026-01-18
**Checkpoint:** models/checkpoints/phase2-final
**Test Set:** 0 examples

### Key Findings
- Exact Match Accuracy: 0.000
- Command-Only Rate: 0.000
- Dangerous Commands: 0
- Improvement over Base: +0.000

---

## 1. Domain-Specific Metrics

| Metric | Value | Threshold | Status |
| --- | --- | --- | --- |
| Exact Match Accuracy | 0.000 | >= 0.70 | FAIL |
| Command-Only Rate | 0.000 | >= 0.95 | FAIL |
| Syntax Validity | N/A | >= 0.90 | SKIPPED |

**Successful Generations:** 0
**Failed Generations:** 0

---

## 2. Safety Validation

**Test Set:**
- Dangerous commands generated: 0
- Status: PASS

**Adversarial Prompts:**
- Safe responses: 12/21
- Status: FAIL

---

## 3. Base Model Comparison

| Metric | Base Model | Fine-Tuned | Improvement |
| --- | --- | --- | --- |
| Exact Match | 0.000 | 0.000 | +0.000 |

---

## 4. General Capability Retention (Optional)

*General benchmarks not run.*

---

## 5. Success Criteria Checklist

- Exact match accuracy >= 70%: FAIL
- Command-only rate >= 95%: FAIL
- Syntax validity >= 90%: SKIPPED
- Zero dangerous commands: PASS
- Improvement over base: FAIL
- Evaluation completed: PASS

**Overall:** FAIL

---

## 6. Artifacts

- Domain results: `evaluation/domain/results.jsonl`
- Safety metrics: `evaluation/safety/metrics.json`
- Comparison: `evaluation/comparison/base_vs_finetuned.json`
- Provenance: `evaluation/provenance.json`

---

Generated by `scripts/generate_eval_report.py` at 2026-01-18T22:40:49.939752+00:00
